{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5: Improving the Pipeline - Updated\n",
    "\n",
    "## Part 2: Analysis\n",
    "\n",
    "The problem is to predict if a project on donorschoose will not get fully funded within 60 days of posting. This prediction is being done at the time of posting, so you can only use data available to you at that time. The data is a file that has one row for each project posted with a column for \"date_posted\" (the date the project was posted) and a column for \"datefullyfunded\" (the date the project was fully funded - assumption for this assignment is that all projects were fully funded eventually). The task is to predict if a project on donorschoose will not get fully funded within 60 days of posting.\n",
    "\n",
    "The data spans Jan 1, 2012 to Dec 31, 2013. You should have your validation/test set be a rolling window of 6 months (which should give you three test sets). The training sets should be everything from 1/1/12 to the beginning of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pipeline_v2 as pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define target \n",
    "target_col = 'not_funded_within_60days'\n",
    "\n",
    "# Define features \n",
    "feature_cols = ['school_city', \n",
    "                'school_state', \n",
    "                'school_metro', \n",
    "                'school_county',\n",
    "                'school_charter', \n",
    "                'school_magnet',\n",
    "                'teacher_prefix',\n",
    "                'primary_focus_subject', \n",
    "                'primary_focus_area', \n",
    "                'resource_type',\n",
    "                'poverty_level', \n",
    "                'grade_level', \n",
    "                'total_price_including_optional_support', \n",
    "                'students_reached', \n",
    "                'eligible_double_your_impact_match']\n",
    "\n",
    "# Define models\n",
    "classifiers = {'LR':  LogisticRegression(),\n",
    "               'KNN': KNeighborsClassifier(), \n",
    "               'DT':  DecisionTreeClassifier(), \n",
    "               'SVM': LinearSVC(), \n",
    "               'RF':  RandomForestClassifier(), \n",
    "               'GB':  GradientBoostingClassifier(), \n",
    "               'AB':  AdaBoostClassifier()} \n",
    "\n",
    "# Define parameters \n",
    "parameters = {'LR':  {'penalty': ['l1','l2'], 'C': [0.001,0.1]}, \n",
    "              'KNN': {'n_neighbors': [5,10], 'weights': ['uniform','distance']}, \n",
    "              'DT':  {'max_depth': [5,10], 'min_samples_split': [5,10]}, \n",
    "              'SVM': {'tol': [0.0001, 0.001], 'C': [0.001,0.1]}, \n",
    "              'RF':  {'n_estimators': [10,100], 'max_depth': [5,10], 'min_samples_split': [5,10]}, \n",
    "              'GB':  {'n_estimators': [10,100], 'learning_rate':[0.001,0.1]}, \n",
    "              'AB':  {'n_estimators': [10,100], 'algorithm': ['SAMME', 'SAMME.R']}}\n",
    "\n",
    "# Define evaluation thresholds \n",
    "thresholds = [0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5]\n",
    "header = ['Split', 'Classifier', 'Parameters', 'Threshold', 'Accuracy', 'Precision', 'Recall', 'F1', 'AUC_ROC']\n",
    "\n",
    "# Define temporal splits \n",
    "start_date = '2012-01-01'\n",
    "end_date = '2013-12-31'\n",
    "date_col = 'date_posted'\n",
    "test_window = pd.Timedelta(6, unit='M')\n",
    "prediction_horizon = pd.Timedelta(60, unit='d') \n",
    "splits = pd.Timedelta(pd.to_datetime(end_date) - pd.to_datetime(start_date)) // test_window "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "df = pd.read_csv('data/projects_2012_2013.csv')\n",
    "\n",
    "# Create target \n",
    "df['datefullyfunded'] = pd.to_datetime(df['datefullyfunded'])\n",
    "df['date_posted'] = pd.to_datetime(df['date_posted'])\n",
    "df['not_funded_within_60days'] = np.where(df['datefullyfunded'] - df['date_posted'] > pd.Timedelta(60, unit='d'), 1, 0)\n",
    "\n",
    "evaluation_table = []\n",
    "\n",
    "# Loop over temporal splits \n",
    "for temporal_split in range(1, splits+1):\n",
    "    \n",
    "    # Split training and testing data\n",
    "    train, test = pipeline.temporal_split(df, start_date, end_date, test_window, prediction_horizon, date_col, temporal_split)\n",
    "    \n",
    "    # Process training and testing data \n",
    "    X_train, X_test, y_train, y_test = pipeline.pre_process(train, test, target_col, feature_cols)\n",
    "\n",
    "    # Loop over classifiers \n",
    "    for clf, model in classifiers.items(): \n",
    "        parameter_values = parameters[clf]\n",
    "\n",
    "        # Loop over parameters \n",
    "        for p in ParameterGrid(parameter_values):\n",
    "            model.set_params(**p)\n",
    "            scores = pipeline.build_classifier(clf, model, X_train, y_train, X_test)\n",
    "    \n",
    "            # Loop over evalaluation thresholds \n",
    "            for k in thresholds: \n",
    "                row = [temporal_split, clf, p]\n",
    "                row.extend(pipeline.metrics_at_k(y_test, scores, k))\n",
    "                evaluation_table.append(row)\n",
    "\n",
    "# Create evaluation table \n",
    "pd.DataFrame(evaluation_table, columns=header).to_csv('evaluation_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-recall curves \n",
    "pipeline.plot_precision_recall_n(y_test, scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
